{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f73742",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548b0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088353f",
   "metadata": {},
   "source": [
    "## test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d0e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scores': tensor([0.9997], grad_fn=<IndexBackward0>), 'labels': tensor([1]), 'boxes': tensor([[ 529.4136, 1095.3047, 1500.0292, 2539.8669]],\n",
      "       grad_fn=<IndexBackward0>)}\n",
      "Detected person with confidence 1.0 at location [529.41, 1095.3, 1500.03, 2539.87]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://images.unsplash.com/photo-1748244487783-5ad28948a7c3?q=80&w=1938&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# you can specify the revision tag if you don't want the timm dependency\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# let's only keep detections with score > 0.9\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fbbde37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1938, 2568)\n"
     ]
    }
   ],
   "source": [
    "print(image.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc06dde",
   "metadata": {},
   "source": [
    "## Explication des coordonnées des boîtes englobantes\n",
    "\n",
    "Les valeurs dans `results[\"boxes\"]` représentent les coordonnées des boîtes englobantes (bounding boxes) qui délimitent les objets détectés dans l'image.\n",
    "\n",
    "**Format des coordonnées :** `[x_min, y_min, x_max, y_max]`\n",
    "\n",
    "- **x_min** : Position horizontale du coin supérieur gauche de la boîte (en pixels)\n",
    "- **y_min** : Position verticale du coin supérieur gauche de la boîte (en pixels)\n",
    "- **x_max** : Position horizontale du coin inférieur droit de la boîte (en pixels)\n",
    "- **y_max** : Position verticale du coin inférieur droit de la boîte (en pixels)\n",
    "\n",
    "**Exemple actuel :** `[529.41, 1095.30, 1500.03, 2539.87]`\n",
    "- La boîte commence à la position (529, 1095) dans l'image\n",
    "- Elle se termine à la position (1500, 2540)\n",
    "- Largeur de la boîte : 1500 - 529 = 971 pixels\n",
    "- Hauteur de la boîte : 2540 - 1095 = 1445 pixels\n",
    "\n",
    "Ces coordonnées sont dans le système de coordonnées de l'image originale (1938 x 2568 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ae948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'N/A', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 12: 'N/A', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 26: 'N/A', 27: 'backpack', 28: 'umbrella', 29: 'N/A', 30: 'N/A', 31: 'handbag', 32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 45: 'N/A', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed', 66: 'N/A', 67: 'dining table', 68: 'N/A', 69: 'N/A', 70: 'toilet', 71: 'N/A', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 83: 'N/A', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
